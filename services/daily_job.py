"""
æ¯æ—¥ä»»åŠ¡æ¨¡å— - è‡ªåŠ¨çˆ¬å–æ–°é—»å¹¶ç”Ÿæˆæ—¥æŠ¥æ€»ç»“
"""
from __future__ import annotations

import os
import json
import re
import requests
from bs4 import BeautifulSoup
from datetime import datetime, timedelta
from urllib.parse import urljoin
from typing import List, Dict, Any, Optional, Literal

from .model_service import get_model_service


class DailyJobService:
    """
    æ¯æ—¥ä»»åŠ¡æœåŠ¡
    - çˆ¬å–æ˜¨å¤©çš„æ–°é—»
    - è°ƒç”¨å¾®è°ƒæ¨¡å‹ç”Ÿæˆæ—¥æŠ¥æ€»ç»“ï¼ˆå­¦ç”Ÿç‰ˆ/æ•™å¸ˆç‰ˆï¼‰
    """
    
    def __init__(
        self,
        news_save_dir: str = "/root/NLP/grab_news/news_days",
        daily_report_dir: str = "/root/NLP/daily_reports",
        base_url: str = "https://dean.xjtu.edu.cn/"
    ):
        self.news_save_dir = news_save_dir
        self.daily_report_dir = daily_report_dir
        self.base_url = base_url
        
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        os.makedirs(self.news_save_dir, exist_ok=True)
        os.makedirs(self.daily_report_dir, exist_ok=True)
    
    def crawl_news_by_date(self, target_date: str = None) -> List[Dict[str, Any]]:
        """
        çˆ¬å–æŒ‡å®šæ—¥æœŸçš„æ–°é—»ï¼Œæ•´åˆäº†åçˆ¬éªŒè¯ç»•è¿‡é€»è¾‘
        
        Args:
            target_date: ç›®æ ‡æ—¥æœŸï¼Œæ”¯æŒæ ¼å¼ï¼š
                - YYYY-MM-DD (å¦‚ 2025-11-27)
                - MM-DD (å¦‚ 11-27ï¼Œé»˜è®¤å½“å‰å¹´ä»½)
                - None (é»˜è®¤æ˜¨å¤©)
        
        Returns:
            æ–°é—»åˆ—è¡¨ï¼Œæ¯æ¡æ–°é—»åŒ…å« id, url, title, content_clean, publish_time ç­‰å­—æ®µ
        """
        # è§£æç›®æ ‡æ—¥æœŸ
        if target_date is None:
            target_mm_dd = (datetime.now() - timedelta(days=1)).strftime('%m-%d')
            target_full = (datetime.now() - timedelta(days=1)).strftime('%Y-%m-%d')
        elif '-' in target_date and len(target_date) == 10:
            # YYYY-MM-DD æ ¼å¼
            target_full = target_date
            target_mm_dd = target_date[5:]  # æå– MM-DD
        elif '-' in target_date and len(target_date) <= 5:
            # MM-DD æ ¼å¼
            target_mm_dd = target_date.zfill(5)  # ç¡®ä¿æ˜¯ MM-DD æ ¼å¼
            current_year = datetime.now().year
            target_full = f"{current_year}-{target_mm_dd}"
        else:
            print(f"âš ï¸ æ— æ³•è§£ææ—¥æœŸæ ¼å¼: {target_date}ï¼Œä½¿ç”¨æ˜¨å¤©")
            target_mm_dd = (datetime.now() - timedelta(days=1)).strftime('%m-%d')
            target_full = (datetime.now() - timedelta(days=1)).strftime('%Y-%m-%d')
        
        print(f"æ­£åœ¨çˆ¬å–æ–°é—»: {self.base_url}")
        print(f"ç›®æ ‡æ—¥æœŸ: {target_mm_dd} ({target_full})")

        # ä½¿ç”¨ grab_news.py ä¸­çš„æ›´ç¨³å¥çš„çˆ¬å–é€»è¾‘
        try:
            from grab_news.grab_news import crawl_news
            
            # ç›´æ¥è°ƒç”¨å°è£…å¥½çš„ crawl_news å‡½æ•°
            # å®ƒä¼šè‡ªåŠ¨å¤„ç† Sessionã€åˆ†é¡µã€è¯¦æƒ…é¡µæŠ“å–å’Œåçˆ¬ç»•è¿‡
            news_data = crawl_news(target_date=target_mm_dd, max_depth=5)
            
            if not news_data:
                print(f"ç›®æ ‡æ—¥æœŸ ({target_mm_dd}) æ²¡æœ‰æ–°é—»")
                return []
            
            print(f"æ‰¾åˆ° {len(news_data)} ä¸ªæ–°é—»æ¡ç›®")
            
            # å¯¹è¿”å›çš„æ•°æ®è¿›è¡Œç®€å•çš„æ ¼å¼åŒ–ï¼Œç¡®ä¿ç¬¦åˆ DailyJobService çš„é¢„æœŸ
            formatted_data = []
            crawl_time = datetime.now().strftime('%Y-%m-%d')
            
            for i, item in enumerate(news_data, 1):
                # ç¡®ä¿ id æ ¼å¼ä¸€è‡´
                item['id'] = f"news_{crawl_time}_{i}"
                
                # ç¡®ä¿ publish_time æ˜¯å®Œæ•´æ—¥æœŸ
                if not item.get('publish_time'):
                     item['publish_time'] = target_full
                elif len(item['publish_time']) == 5: # åªæœ‰ MM-DD
                     current_year = datetime.now().year
                     item['publish_time'] = f"{current_year}-{item['publish_time']}"
                
                formatted_data.append(item)
            
            # ä¿å­˜æ–°é—»æ•°æ®
            if formatted_data:
                filename = f"news_{target_mm_dd.replace('-', '')}.json"
                save_path = os.path.join(self.news_save_dir, filename)
                with open(save_path, 'w', encoding='utf-8') as f:
                    json.dump(formatted_data, f, ensure_ascii=False, indent=2)
                print(f"\nâœ“ å·²ä¿å­˜ {len(formatted_data)} æ¡æ–°é—»åˆ°: {save_path}")
            
            return formatted_data

        except ImportError:
            print("âš ï¸ æ— æ³•å¯¼å…¥ grab_news æ¨¡å—ï¼Œå›é€€åˆ°æ™®é€šçˆ¬å–æ¨¡å¼")
            return []
        except Exception as e:
            print(f"âœ— çˆ¬å–è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            return []
    
    def crawl_yesterday_news(self) -> List[Dict[str, Any]]:
        """çˆ¬å–æ˜¨å¤©çš„æ–°é—»ï¼ˆå…¼å®¹æ—§æ¥å£ï¼‰"""
        return self.crawl_news_by_date(target_date=None)
    
    def load_news_from_file(self, target_date: str) -> Optional[List[Dict[str, Any]]]:
        """
        ä»å·²ä¿å­˜çš„æ–‡ä»¶åŠ è½½æ–°é—»æ•°æ®
        
        Args:
            target_date: ç›®æ ‡æ—¥æœŸ (YYYY-MM-DD æˆ– MM-DD)
        
        Returns:
            æ–°é—»åˆ—è¡¨ï¼Œå¦‚æœæ–‡ä»¶ä¸å­˜åœ¨è¿”å› None
        """
        # è§£ææ—¥æœŸè·å– MM-DD æ ¼å¼
        if len(target_date) == 10:
            mm_dd = target_date[5:]
        else:
            mm_dd = target_date.zfill(5)
        
        filename = f"news_{mm_dd.replace('-', '')}.json"
        file_path = os.path.join(self.news_save_dir, filename)
        
        if os.path.exists(file_path):
            print(f"ğŸ“‚ ä»æ–‡ä»¶åŠ è½½æ–°é—»: {file_path}")
            with open(file_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        
        return None
    
    def _clean_content(self, content_div) -> str:
        """æ¸…æ´—HTMLå†…å®¹ï¼Œæå–çº¯æ–‡æœ¬"""
        # å¤„ç†æ®µè½æ ‡ç­¾
        for p_tag in content_div.find_all(['p', 'div']):
            if p_tag.get_text(strip=True):
                p_tag.append('\n')
        
        content_text = content_div.get_text(separator=' ', strip=True)
        
        # æ¸…ç†å¤šä½™ç©ºç™½
        content_text = re.sub(r' +', ' ', content_text)
        content_text = re.sub(r' \n', '\n', content_text)
        content_text = re.sub(r'\n ', '\n', content_text)
        content_text = re.sub(r'\n{2,}', '\n', content_text)
        content_text = content_text.strip()
        
        # æ¸…ç†æ¯è¡Œ
        lines = content_text.split('\n')
        cleaned_lines = []
        for line in lines:
            line = line.strip()
            if line:
                line = re.sub(r'\s+', ' ', line)
                cleaned_lines.append(line)
        
        return '\n'.join(cleaned_lines)
    
    def generate_daily_report(
        self,
        news_list: List[Dict[str, Any]],
        date_str: Optional[str] = None
    ) -> Dict[str, str]:
        """
        ç”Ÿæˆæ¯æ—¥æ–°é—»æ€»ç»“æŠ¥å‘Šï¼ˆå­¦ç”Ÿç‰ˆ + æ•™å¸ˆç‰ˆï¼‰
        
        Args:
            news_list: æ–°é—»åˆ—è¡¨
            date_str: æ—¥æœŸå­—ç¬¦ä¸² (YYYY-MM-DD)
        
        Returns:
            åŒ…å« student_summary å’Œ teacher_summary çš„å­—å…¸
        """
        if not news_list:
            return {
                "date": date_str or datetime.now().strftime('%Y-%m-%d'),
                "student_summary": "ä»Šæ—¥æ— é‡è¦æ–°é—»é€šçŸ¥ã€‚",
                "teacher_summary": "ä»Šæ—¥æ— é‡è¦æ–°é—»é€šçŸ¥ã€‚"
            }
        
        if not date_str:
            date_str = news_list[0].get('publish_time', datetime.now().strftime('%Y-%m-%d'))
        
        # æ„å»ºè¾“å…¥æ–‡æœ¬
        blocks = [f"ã€æ—¥æœŸã€‘{date_str}"]
        for idx, news in enumerate(news_list, 1):
            blocks.append(
                f"ã€æ–°é—»{idx}ã€‘\n"
                f"æ ‡é¢˜ï¼š{news.get('title', '')}\n"
                f"æ¥æºï¼š{news.get('source', 'æ•™åŠ¡å¤„')}\n"
                f"å‘å¸ƒæ—¶é—´ï¼š{news.get('publish_time', '')}\n"
                f"æ­£æ–‡ï¼š\n{news.get('content_clean', '')[:2000]}\n"  # é™åˆ¶é•¿åº¦
            )
        
        news_content = "\n".join(blocks)
        
        # è·å–æ¨¡å‹æœåŠ¡
        model_service = get_model_service()
        
        print("\næ­£åœ¨ç”Ÿæˆå­¦ç”Ÿç‰ˆæ—¥æŠ¥...")
        student_summary = model_service.summarize_news(news_content, user_identity="student")
        
        print("æ­£åœ¨ç”Ÿæˆæ•™å¸ˆç‰ˆæ—¥æŠ¥...")
        teacher_summary = model_service.summarize_news(news_content, user_identity="teacher")
        
        # è®¡ç®—æœ‰æ•ˆæ–°é—»æ•°é‡ï¼ˆåŸºäºæ‘˜è¦ä¸­çš„æ ‡é¢˜æ•°é‡ï¼‰
        student_effective_count = student_summary.count("### ")
        teacher_effective_count = teacher_summary.count("### ")
        
        report = {
            "date": date_str,
            "news_count": len(news_list),
            "student_effective_count": student_effective_count,
            "teacher_effective_count": teacher_effective_count,
            "student_summary": student_summary,
            "teacher_summary": teacher_summary,
            "generated_at": datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        }
        
        # ä¿å­˜æ—¥æŠ¥
        report_filename = f"report_{date_str}.json"
        report_path = os.path.join(self.daily_report_dir, report_filename)
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        print(f"\nâœ“ æ—¥æŠ¥å·²ä¿å­˜åˆ°: {report_path}")
        
        return report
    
    def run_daily_job(self, target_date: str = None) -> Dict[str, Any]:
        """
        æ‰§è¡Œå®Œæ•´çš„æ¯æ—¥ä»»åŠ¡æµç¨‹
        
        Args:
            target_date: ç›®æ ‡æ—¥æœŸ (YYYY-MM-DD æˆ– MM-DD)ï¼Œé»˜è®¤ä¸ºæ˜¨å¤©ã€‚
                        å¦‚æœä¼ å…¥ "today"ï¼Œåˆ™å¤„ç†ä»Šå¤©ã€‚
        
        Returns:
            ä»»åŠ¡æ‰§è¡Œç»“æœï¼ŒåŒ…å«çˆ¬å–çš„æ–°é—»æ•°é‡å’Œç”Ÿæˆçš„æ—¥æŠ¥
        """
        # è§£æç›®æ ‡æ—¥æœŸ
        if target_date == "today":
            target_full = datetime.now().strftime('%Y-%m-%d')
            date_display = "ä»Šå¤©"
        elif target_date is None:
            target_full = (datetime.now() - timedelta(days=1)).strftime('%Y-%m-%d')
            date_display = "æ˜¨å¤©"
        elif '-' in target_date and len(target_date) == 10:
            target_full = target_date
            date_display = target_date
        elif '-' in target_date:
            mm_dd = target_date.zfill(5)
            current_year = datetime.now().year
            target_full = f"{current_year}-{mm_dd}"
            date_display = target_full
        else:
            target_full = (datetime.now() - timedelta(days=1)).strftime('%Y-%m-%d')
            date_display = "æ˜¨å¤©"
        
        print("=" * 60)
        print(f"ã€æ¯æ—¥ä»»åŠ¡å¯åŠ¨ã€‘ {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"ã€ç›®æ ‡æ—¥æœŸã€‘ {date_display} ({target_full})")
        print("=" * 60)
        
        # Step 1: å°è¯•ä»æ–‡ä»¶åŠ è½½ï¼Œå¦‚æœæ²¡æœ‰åˆ™çˆ¬å–
        print(f"\nğŸ“° Step 1: è·å– {target_full} çš„æ–°é—»")
        news_list = self.load_news_from_file(target_full)
        
        if news_list is None:
            print("æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå¼€å§‹çˆ¬å–...")
            news_list = self.crawl_news_by_date(target_date=target_full)
        else:
            print(f"âœ“ ä»æ–‡ä»¶åŠ è½½äº† {len(news_list)} æ¡æ–°é—»")
        
        if not news_list:
            print(f"\nâš ï¸ {target_full} æ²¡æœ‰æ–°é—»ï¼Œç”Ÿæˆç©ºæ—¥æŠ¥")
            # ç”Ÿæˆç©ºæ—¥æŠ¥
            empty_report = {
                "date": target_full,
                "news_count": 0,
                "student_summary": "ä»Šæ—¥æ— é‡è¦æ–°é—»é€šçŸ¥ã€‚",
                "teacher_summary": "ä»Šæ—¥æ— é‡è¦æ–°é—»é€šçŸ¥ã€‚",
                "generated_at": datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            }
            # ä¿å­˜ç©ºæ—¥æŠ¥
            report_filename = f"report_{target_full}.json"
            report_path = os.path.join(self.daily_report_dir, report_filename)
            with open(report_path, 'w', encoding='utf-8') as f:
                json.dump(empty_report, f, ensure_ascii=False, indent=2)
            print(f"âœ“ ç©ºæ—¥æŠ¥å·²ä¿å­˜åˆ°: {report_path}")
            
            return {
                "status": "no_news",
                "news_count": 0,
                "report": empty_report
            }
        
        # Step 2: ç”Ÿæˆæ—¥æŠ¥
        print("\nğŸ“ Step 2: ç”Ÿæˆæ—¥æŠ¥æ€»ç»“")
        report = self.generate_daily_report(news_list, date_str=target_full)
        
        print("\n" + "=" * 60)
        print("ã€æ¯æ—¥ä»»åŠ¡å®Œæˆã€‘")
        print(f"  - æ–°é—»æ•°é‡: {len(news_list)}")
        print(f"  - æ—¥æŠ¥æ—¥æœŸ: {report['date']}")
        print("=" * 60)
        
        return {
            "status": "success",
            "news_count": len(news_list),
            "report": report
        }
    
    def get_report_by_date(self, date_str: str) -> Optional[Dict[str, Any]]:
        """
        è·å–æŒ‡å®šæ—¥æœŸçš„æ—¥æŠ¥
        
        Args:
            date_str: æ—¥æœŸå­—ç¬¦ä¸² (YYYY-MM-DD)
        
        Returns:
            æ—¥æŠ¥å†…å®¹ï¼Œå¦‚æœä¸å­˜åœ¨è¿”å› None
        """
        report_path = os.path.join(self.daily_report_dir, f"report_{date_str}.json")
        if os.path.exists(report_path):
            with open(report_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        return None
    
    def get_recent_reports(self, days: int = 7) -> List[Dict[str, Any]]:
        """
        è·å–æœ€è¿‘Nå¤©çš„æ—¥æŠ¥
        
        Args:
            days: å¤©æ•°
        
        Returns:
            æ—¥æŠ¥åˆ—è¡¨ï¼ˆæŒ‰æ—¥æœŸå€’åºï¼‰
        """
        reports = []
        today = datetime.now().date()
        
        for i in range(days):
            date = today - timedelta(days=i)
            date_str = date.isoformat()
            report = self.get_report_by_date(date_str)
            if report:
                reports.append(report)
        
        return reports


    def generate_weekly_report(
        self,
        end_date_str: str,
    ) -> Dict[str, Any]:
        """
        ç”Ÿæˆå‘¨æŠ¥ï¼ˆè¿‡å»7å¤©ï¼‰
        
        Args:
            end_date_str: ç»“æŸæ—¥æœŸ (YYYY-MM-DD)
            
        Returns:
            å‘¨æŠ¥æ•°æ®
        """
        try:
            end_date = datetime.strptime(end_date_str, '%Y-%m-%d')
        except ValueError:
            # å¦‚æœæ ¼å¼ä¸å¯¹ï¼Œé»˜è®¤ä»Šå¤©
            end_date = datetime.now()
            end_date_str = end_date.strftime('%Y-%m-%d')
            
        start_date = end_date - timedelta(days=6) # 7 days including end_date
        
        week_summaries = []
        news_count_total = 0
        
        print(f"æ­£åœ¨ç”Ÿæˆå‘¨æŠ¥: {start_date.strftime('%Y-%m-%d')} ~ {end_date_str}")
        
        for i in range(7):
            current_date = start_date + timedelta(days=i)
            date_s = current_date.strftime('%Y-%m-%d')
            report = self.get_report_by_date(date_s)
            
            # å¦‚æœæ—¥æŠ¥ä¸å­˜åœ¨ï¼Œå°è¯•ç°åœºæŠ“å–å¹¶ç”Ÿæˆ
            if not report:
                print(f"  - {date_s} æ—¥æŠ¥ç¼ºå¤±ï¼Œæ­£åœ¨å°è¯•è‡ªåŠ¨è¡¥å…¨...")
                try:
                    # run_daily_job ä¼šå¤„ç†çˆ¬å–å’Œç”Ÿæˆ
                    job_result = self.run_daily_job(target_date=date_s)
                    report = job_result.get("report")
                except Exception as e:
                    print(f"  âš ï¸ è‡ªåŠ¨è¡¥å…¨ {date_s} æ—¥æŠ¥å¤±è´¥: {e}")
            
            if report and report.get('news_count', 0) > 0:
                news_count_total += report.get('news_count', 0)
                week_summaries.append({
                    "date": date_s,
                    "student": report.get("student_summary", ""),
                    "teacher": report.get("teacher_summary", "")
                })
        
        if not week_summaries:
             return {
                "start_date": start_date.strftime('%Y-%m-%d'),
                "end_date": end_date_str,
                "news_count": 0,
                "student_summary": "æœ¬å‘¨æ— é‡è¦æ–°é—»é€šçŸ¥ã€‚",
                "teacher_summary": "æœ¬å‘¨æ— é‡è¦æ–°é—»é€šçŸ¥ã€‚",
                "generated_at": datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            }

        # æ‹¼æ¥æ¯æ—¥æ€»ç»“ä½œä¸ºè¾“å…¥
        combined_text_student = ""
        combined_text_teacher = ""
        
        for item in week_summaries:
            combined_text_student += f"ã€{item['date']}ã€‘\n{item['student']}\n\n"
            combined_text_teacher += f"ã€{item['date']}ã€‘\n{item['teacher']}\n\n"
            
        model_service = get_model_service()
        
        # ä½¿ç”¨ summarize_news ç”Ÿæˆå‘¨æŠ¥ï¼Œä½†æ·»åŠ å‰ç¼€è¯´æ˜è¿™æ˜¯å‘¨æŠ¥
        # ä¸ºäº†è®©æ¨¡å‹çŸ¥é“è¿™æ˜¯æ±‡æ€»ï¼Œæˆ‘ä»¬å¯ä»¥ç¨å¾®åŒ…è£…ä¸€ä¸‹ summarize_news æˆ–è€…ç›´æ¥ç”¨
        # è¿™é‡Œç›´æ¥ç”¨ï¼Œå› ä¸º summarize_news çš„ prompt æ¯”è¾ƒé€šç”¨ ("è¯·æ€»ç»“ä»¥ä¸‹æ•™åŠ¡é€šçŸ¥")
        
        print("  - ç”Ÿæˆå­¦ç”Ÿç‰ˆå‘¨æŠ¥...")
        weekly_student = model_service.summarize_news(
            f"ä»¥ä¸‹æ˜¯è¿‡å»ä¸€å‘¨çš„æ¯æ—¥æ–°é—»æ€»ç»“ï¼Œè¯·æ ¹æ®å®ƒä»¬ç”Ÿæˆä¸€ä»½å‘¨æŠ¥ï¼š\n\n{combined_text_student}", 
            user_identity="student"
        )
        
        print("  - ç”Ÿæˆæ•™å¸ˆç‰ˆå‘¨æŠ¥...")
        weekly_teacher = model_service.summarize_news(
            f"ä»¥ä¸‹æ˜¯è¿‡å»ä¸€å‘¨çš„æ¯æ—¥æ–°é—»æ€»ç»“ï¼Œè¯·æ ¹æ®å®ƒä»¬ç”Ÿæˆä¸€ä»½å‘¨æŠ¥ï¼š\n\n{combined_text_teacher}", 
            user_identity="teacher"
        )
        
        student_effective_count = weekly_student.count("### ")
        teacher_effective_count = weekly_teacher.count("### ")

        return {
            "start_date": start_date.strftime('%Y-%m-%d'),
            "end_date": end_date_str,
            "news_count": news_count_total,
            "student_summary": weekly_student,
            "teacher_summary": weekly_teacher,
            "student_effective_count": student_effective_count,
            "teacher_effective_count": teacher_effective_count,
            "generated_at": datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        }


# ä¾¿æ·å‡½æ•°
def run_daily_job() -> Dict[str, Any]:
    """æ‰§è¡Œæ¯æ—¥ä»»åŠ¡"""
    service = DailyJobService()
    return service.run_daily_job()


if __name__ == "__main__":
    run_daily_job()

